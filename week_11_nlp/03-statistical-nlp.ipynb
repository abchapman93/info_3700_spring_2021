{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from medspacy.visualization import visualize_ent, MedspaCyVisualizerWidget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In the last notebook, we used rule-based matching to extract mentions of treatments and problems from patient texts. One disadvantage of rule-based systems is that it can take a long time to manually curate all of the rules, particularly if the classes you're extracting are very broad and have many variants.\n",
    "\n",
    "Another approach is **statistical NLP**. In this approach, we **annotate** a large corpus of text to identify the concepts we're interested in. Then we use those annotations as examples to train a machine learning model. In the machine learning module, we used ML to predict binary outcomes (0 or 1) for whether patients have conditions. In NER, a machine learning model predicts a label for each word in a sequence.\n",
    "\n",
    "## i2b2\n",
    "The NLP community hosts many **shared tasks**. These are competitions where multiple teams are given the same data and instructions and build different systems. These datasets include **gold standard annotations**, which are large sets of annotated examples.\n",
    "\n",
    "To train a statistical model, I used data from the i2b2 2012 shared task: [**\"Evaluating temporal relations in clinical text\"**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756273/). This model was trained on data for the first subtask in the shared task, referred to in the challenge as **\"Clinically relevant events\"**. For the purpose of this module, I specifically restricted it to the following labels of **clinical concepts**:\n",
    "- **Problems:** Diagnoses, signs, and symptoms\n",
    "- **Tests:** Lab and vital measurements\n",
    "- **Treatments:** Medications, procedures, and therapies\n",
    "\n",
    "\n",
    "If you're interested in seeing how to train this model, see this notebook: [./appendix-train-i2b2-ner.ipynb](./appendix-train-i2b2-ner.ipynb). If you would like get access to the data for the challenge so you can actually train the model yourself, fill out this data access form on the i2b2 website: https://portal.dbmi.hms.harvard.edu/. Once you're approved, you can download the XML files and change the path variables in the notebook to read in the original data sources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our model\n",
    "We use our model by using `spacy.load`, just like we would normally read in a default spaCy model. Make sure that you installed this in the [introduction](./00-introduction.ipynb) notebook. I named this model **\"en_info_3700_i2b2_2012\"**. The **\"en\"** stands for **\"English\"** (every spaCy model needs to start with its language), and the rest is named after the class and shared task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_info_3700_i2b2_2012\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline looks similar to the regular spaCy pipeline. But let's look at what labels are included in the `ner` component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our i2b2 model in the exact same way that we would use any other model. Let's call our clinical model on an example text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The patient was started on abx for his infection\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what entities were extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model extracted two clinical entities: **\"abx\"**, a **treatment**, and **\"his infection\"**, a **problem**. \n",
    "\n",
    "Let's now process a few more documents and view the model output. We'll combine all of the following sentences and process them all as one `doc` so that we can view all the output simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"87-year-old man with htn and end-stage renal disease.\",\n",
    "    \"His wife recently died from end stage renal disease.\",\n",
    "    \"The patient was started on abx for his infection.\",\n",
    "    \"There is continued mild-to-moderate congestive heart failure. \",\n",
    "    \"The patient is s/p median sternotomy and right thoracotomy.\",\n",
    "    \"The pt presents for ckd stage 4\",\n",
    "    \"He previously had CKD stage 3.\",\n",
    "    \"The patient presented to the emergency room with cough and fever, concern for infections.\",\n",
    "    \"Patient prescribed coumadin for her atrial fibrillation.\",\n",
    "    \"Patient prescribed coumadin for her AF.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = MedspaCyVisualizerWidget(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0 # Change this to go through the docs\n",
    "# visualize_ent(docs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Look at the output of the model above. Do you see any errors in the predictions? Are there any other limitations to the information extracted by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "### Discussion\n",
    "Do you see any issues with the example below? Did the model predict correctly? Is there any other information we need to extract from the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"There is no evidence of pneumonia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "We now have access to a statistical model which can identify clinical concepts reasonably well. However, we've also seen that that is sometimes not enough. Clinical documentation is full of instances where a concept is mentioned but is not necessarily present or relevant to the visit, such as the example above. In the next notebook, we'll see how to look for additional contextual information in a sentence and how we can use that to exclude concepts which are negated or not current.\n",
    "\n",
    "[./04-context.ipynb](./04-context.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
