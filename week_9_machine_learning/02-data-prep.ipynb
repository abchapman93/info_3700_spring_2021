{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In the last step, we analyzed our data and found a few issues with some of the columns. Before we start training our machine learning models, we should fix up these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "No dataset is perfect. When you look at some of our features, you might notice that not everything makes sense. For example, if you look at the minimum of some of these columns, you notice that some patients have a BMI and blood pressure of 0. Does that sound right?\n",
    "\n",
    "Chances are these are **missing values**: those patients don't really have a BMI of 0, but maybe the researchers didn't collect those patient's BMI and so just put 0 in as a subsitute. \n",
    "You might also see these as \"NaN\", meaning \"not a number\", but in this case they were assigned a value of 0.\n",
    "\n",
    "## Questions to discuss\n",
    "- Why might these values be missing?\n",
    "- Does every column with a \"0\" mean that that's a missing value?\n",
    "- What are some potential problems of building a classifier with missing values?\n",
    "- What should we do about them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Impute the missing values by finding the mean of the columns.\n",
    "- Specify which columns have missing values. Save this to a list called `cols_with_missing_vals`\n",
    "- Loop through these columns in the DataFrame\n",
    "- For each column, filter to rows where the value is not **0**. We don't want the 0's to artificially lower the mean\n",
    "- Replace the 0's with the imputed value by using the `.replace()` method of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ____:\n",
    "    not_missing = df[df[col] != __] \n",
    "    imputed_value = not_missing[col].____()\n",
    "    df[col] = df[col].replace(__, ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels and features\n",
    "Next, we need to separate our data into two separate variables. The first are the **features** and the second are called labels.\n",
    "\n",
    "## Features\n",
    "The **\"features\"** in a dataset are the information collected for each data point. This is the data which we'll provide to our model to learn from. The features are also known as the *independent variables*.\n",
    "### Discussion\n",
    "Which column(s) the **features** of our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "The **label** signifies what **class** each row belongs to. This is also known as the *dependent variable* In our task, **\"1\"** means that the patient has diabetes (positive class), while a **\"0\"** means that the patient does not have diabetes (negative class). This is contained in the \"**Outcome**\" column.\n",
    "\n",
    "By convention, the features are usually called **`X`**, while the labels are called **`y`**.\n",
    "\n",
    "### TODO\n",
    "Split out DataFrame up into two variables, `X` and `y`. Create `X` by calling `df.drop()` and passing in a list of columns which shouldn't be included in your features. Create `y` by accessing the column containing the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([____], axis=1)\n",
    "y = df[____]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train Split\n",
    "We'll also split up our dataset into a *train* and *test* set. Our ultimate goal is to be able to predict whether a set of brand-new patients has diabetes. These new patients have never been seen before by our classifier. \n",
    "\n",
    "A common practice in machine learning development is to take a portion of our data and leave those rows out during training, then we'll see how our classifiers perform on these rows.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets\n",
    "\n",
    "## Questions to discuss\n",
    "- Why is it important  to evaluate on testing data that is separate from our training data?\n",
    "- How should you select the data that you'll leave out for testing?\n",
    "- What are the costs of taking out data for testing?\n",
    "- What proportions should be used for testing and training?\n",
    "\n",
    "### TODO\n",
    "- Split up X and y in to corresponding train and test sets using the `train_test_split` method from sklearn. \n",
    "- The training set should contain **80%** of the data, while the testing set should contain **20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data\n",
    "from sklearn.model_selection import ____\n",
    "X_train, X_test, y_train, y_test = ____(X, y, train_size=__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save our dataset\n",
    "In our next notebook, we'll start doing actual machine learning on our dataset. But since we've done so much work cleaning up and splitting our dataset, we'll save our processed data to disk so that we can load it in without having to redo all of these steps.\n",
    "\n",
    "Using the Python `pickle` package, save the dataset to a file called **\"diabetes_data.pkl\"**. `pickle` is a serialization package in Python and can be used to save Python objects to disk and then reload them in another session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"diabetes_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train, X_test, y_train, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "Now that we have our data prepared, we're finally ready to do some machine learning! In our final in-class notebook, we will trained models on our dataset and evaluate to see how well they perform.\n",
    "\n",
    "[./03-model-training-and-evaluation.ipynb](./03-model-training-and-evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
