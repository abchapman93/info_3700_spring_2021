{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this final notebook, we'll explore `pandas` and use it to load data, transform it, perform analysis, and create visualizations. This notebook will be much more interactive than the previous ones, so get ready to code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas\n",
    "\n",
    "One great library for working with data in Python is `pandas` (pronounced \"pan-dis\" - not like the bear). Pandas offers high-performance data structures for processing data in a tabular format. It is one of the most useful tools for a data scientist and we'll use it frequently throughout this course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and viewing data\n",
    "In the previous notebook, we were working with small samples of dummy data. We'll often want to load data from another source before analyzing it.\n",
    "\n",
    "\n",
    "10 data points is not enough to do any real analysis or gain any interesting insights. Let's instead use the entire dataset. This dataset has been saved to this directory as **\"500_Person_Gender_Height_Weight_Index.csv\"**. It originally came from [Kaggle](https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/data).\n",
    "\n",
    "We'll start by reading in the csv file containing the data. Pandas can read files of a number data types. First, import pandas with the alias `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's re-import our visualization modules\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, call the function `read_csv` with the filepath as an argument. Save the result as `df` (short for **\"dataframe\"**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"500_Person_Gender_Height_Weight_Index.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at what the data looks like. We can look at the first 5 rows of a dataframe by calling the dataframe's `head` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at this, we can see that there are 4 columns. Most are explanatory, but the **Index** variable may need some additional explanation. This is provided on Kaggle's website:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index :\n",
    "\n",
    "0 - Extremely Weak\n",
    "\n",
    "1 - Weak\n",
    "\n",
    "2 - Normal\n",
    "\n",
    "3 - Overweight\n",
    "\n",
    "4 - Obesity\n",
    "\n",
    "5 - Extreme Obesity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- Height is in cm\n",
    "- Weight is in Kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to looking at the first rows, let's get a summary of the dataset as a whole. We can get summary statistics of any numerical columns by calling `df.describe`. This gives the count, mean, standard deviation, min/max, and quantile information for each variable. Note that **\"Gender\"** is not included here - we'll have to do some additional analysis later for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a single column by indexing with the column's name, similar to getting the value in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column\n",
    "df[\"Gender\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call methods on that specific column. For example, we can get descriptive statistics like the min, max, and mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Height\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Height\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Height\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Get the mean, min, and max values of the **\"Weight\"** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "df[____].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min\n",
    "df[\"Weight\"].____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max\n",
    "df[___].____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Accessing Certain Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get specific rows by using a numerical index on the `df.iloc` attribute. This functions the same as lists or other ordered arrays in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the first row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 5-10\n",
    "df.iloc[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The height and weight for the first 10 rows:\n",
    "df.iloc[:10][[\"Height\", \"Weight\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating by Variables\n",
    "We can call methods on the columns of a DataFrame to do additional analysis on specific variables. Let's look at two categorical variables: **Gender** and **Index**. With categorical variables, we might want to get the count of rows where the variable takes on a certain value. For example, how many rows are **Male** vs. **Female**?\n",
    "\n",
    "One way to do this is by using the `groupby` method. We group the dataframe by a column name and then call `size()` to get the count. The cell below shows how to do this with the **\"Gender\"** column. \n",
    "\n",
    "**Note**: This is the equivalent in SQL of using  `GROUP BY` clause:\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    Gender, COUNT(*)\n",
    "FROM bmi\n",
    "GROUP BY Gender\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Gender\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Get the count of each value of **Index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.____(\"Index\").____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling operations on columns and assigning new columns\n",
    "We can add, subtract, or do other operations on pandas columns, just like we can with other variables. For example, multiplying a column by a scalar value will multiply each element of the column by that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Height\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Height\"].head() * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same works for addition. Note that this will work the same way as the datatype of the elements. Remember how we added two strings together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"This person is \" +  df[\"Gender\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform operations using multiple columns. \n",
    "\n",
    "Let's use the height and weight columns to create a new column with **BMI** measurements. BMI is calculated from height and weight using this equation:\n",
    "\n",
    "$$BMI = \\frac{Weight (kg)}{Height (m) ^ 2}$$\n",
    "\n",
    "#### TODO\n",
    "To get the BMI measurement, we'll need to go through a few steps:\n",
    "1. Convert **Height** from centimers to meters. We'll save this as a new variabled called `height_m`\n",
    "2. Square the **Height in meters** column. Save this as a variable `height_m_sqrd`\n",
    "3. Divide the **Weight** column by the **Height in meters** column. Save this as a variabled called `bmi`\n",
    "4. Assign the result to a new column in `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Convert Height from centimers to meters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_m = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Square the *Height in meters* column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square height_m\n",
    "height_m_sqrd = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Divide the *Weight* column by the *Height in meters* column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the weight column by the height in meters squared\n",
    "bmi = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Assign the result to a new column in `df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add as a column in the DataFrame\n",
    "df[___] = bmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have a column called **BMI** in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Plotting\n",
    "Pandas also contains useful methods for plotting the data in dataframes. When combined with seaborn, this allows us to create powerful visualizations using datasets. Let's generate a histogram to look at the distribution of the BMI which we just calculated:\n",
    "\n",
    "#### Discussion\n",
    "Does this histogram show a **normal** distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BMI\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Generate histograms for the height and weight columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height\n",
    "df[____].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a histogram for the **Index** and **Gender** columns, which are categorical, let's generate bar graphs. We can first get the count of values of male vs. female patients by calling the `groupby().size()` method, then calling `.plot.bar()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Gender\").size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn's version of the barplot is called `countplot` and will assign a different color to each bar. We provide the dataframe in the `data` keywoard argument and specify the column to use in the `x` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Gender\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Create bar graphs for the **Index** column using both `.plot.bar()` and `sns.countplot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.____(\"Index\").____().plot.____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=____, ____=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean indexing\n",
    "Earlier, we saw how we can access specific subsets of the data using column names or row indices. Next, we'll see how we can filter the dataset based on conditions. \n",
    "\n",
    "Let's say we want to de-aggregate the data by sex so that we can compare statistics between the female and male populations. It would be useful to separate these data points into two separate dataframes so we can compare them. **Boolean indexing** allows us to evaluate a condition and then filter to rows where that condition is True.\n",
    "\n",
    "Here is the general syntax for filtering based on whether a column is equal to some value:\n",
    "\n",
    "```python\n",
    "df[df[\"column_name\"] == value]\n",
    "```\n",
    "\n",
    "... or greater than:\n",
    "```python\n",
    "df[df[\"column_name\"] > value]\n",
    "```\n",
    "\n",
    "... and so on.\n",
    "\n",
    "Here is an example using our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = df[df[\"Gender\"] == \"Female\"]\n",
    "male = df[df[\"Gender\"] == \"Male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Create two new dataframes: `norm` and `sev_obese`. `norm` contains all rows which have an **Index** of 2 (normal BMI) and `sev_obese` contains rows with an **Index** of 5 (severely obese). We can then compare and contrast the other measurements for these two populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm = df[df[____] == 2]\n",
    "____ = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_obese.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the height and weights of these two groups. In the cell below, the code to plot the height and weight for `norm` has already been completed. Uncomment the second line of code and edit it so you can plot the `sev_obese` group as well. Use a different color for each group and fill in the label keyword argument so we can visually differentiate between the two groups.\n",
    "\n",
    "Note that we are using the same plot figure to plot both scatterplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = norm.plot.scatter(x=\"Weight\", y=\"Height\", color=\"C0\", label=\"Normal Weight\")\n",
    "# ax = ____.plot.scatter(x=\"Weight\", ____, ____=____, ax=ax, label=____)\n",
    "\n",
    "# Increase the plot size\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "Let's now do the same using a histogram to compare the distribution of weight of the two populations. We'll use `sns.displot` so that we can see the kernel density estimate of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(norm[\"Weight\"], label=\"Normal BMI\")\n",
    "sns.distplot(____[\"Weight\"], ax=ax, ____=\"Severely Obese\")\n",
    "ax.legend()\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "If you feel you need additional review of Python and SQL, there are two additional notebooks in this directory for quick review:\n",
    "\n",
    "- [./03-python_review](./03-python_review.ipynb)\n",
    "- [./04-sql_review](./04-sql_review.ipynb)\n",
    "\n",
    "See Canvas for the homework assignment for next week.\n",
    "\n",
    "Next week, we'll start to use **MIMIC-II**, a deidentified clinical database containing real-world data from an EHR. We'll combine Python and SQL to query this database and apply these tools we learned today to analyze medical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
