{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's connect to our database\n",
    "username = \"\" # Enter your username here\n",
    "conn = pymysql.connect(host=\"35.233.174.193\",port=3306,\n",
    "                       user=username,\n",
    "                       passwd=getpass.getpass(\"Enter password for MIMIC2 database\"),\n",
    "                       db='mimic2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs\n",
    "Lab tests are used for diagnostic purposes. In MIMIC, the lab measurements are stored in `labevents`. Let's look at the first 10 rows of this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM labevents LIMIT 10;\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata about the tests, such as a LOINC code and description, are stored in a separate table called `d_labitems`. This is common in relational database modeling. Let's look at the first 10 rows of `d_labitems`. Note that there is information about the test, but no actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM d_labitems LIMIT 10;\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the test metadata along with the test results, we can join these two tables together using the **\"itemid\"** column. \n",
    "\n",
    "### TODO\n",
    "Join the `labevents` and `d_labitems`. Select the top 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM labevents\n",
    "    ____ ____ d_labitems\n",
    "        ON labevents.itemid = ____.itemid\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on a specific lab test. We'll look at the LOINC code [2345-7](https://loinc.org/2345-7/), which measures the amount of glucose in a patient's blood. This test is relevant for testing whether a patient has diabetes. Here is a description from the LOINC website:\n",
    "***\n",
    "<strong>\n",
    "Glucose (C6H12O6) is a simple monosaccharide and monomer of carbohydrates. Glucose provides energy for cellular processes and aids metabolism within the body. When food is ingested, the carbohydrates within the food are broken down into glucose molecules. Blood glucose content is significant in determining an individual's overall state of health. An elevated blood glucose level is called hyperglycemia and a deficient blood glucose level is called hypoglycemia. When an individual is hyperglycemic and cannot properly regulate their blood glucose level they are considered diabetic. Type 1 diabetes is caused by the immune system attacking pancreatic beta cells (cells that produce insulin) and Type 2 diabetes is caused by insulin resistance. [MedlinePlus Encyclopedia:003482]\n",
    "</strong>\n",
    "***\n",
    "\n",
    "Let's specifically analyze the results of this test and generate some descriptive statistics. \n",
    "\n",
    "### TODO\n",
    "1. Join `labevents` and `d_labitems` and filter to rows where the LOINC code is **'2345-7'**. Limit to 10 rows to get a preview\n",
    "2. Using SQL, select the **minimum**, **maximum**, and **average** values of this test\n",
    "3. Using Python, select the first 10,000 rows. Call the resulting DataFrame `glucose`\n",
    "4. Generate descriptive statistics of the DataFrame\n",
    "5. Generate a box plot with Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join labevents and d_labitems and filter to rows where the LOINC code is '2345-7'. \n",
    "# Limit to 10 rows to get a preview\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM labevents\n",
    "    ____ ____ d_labitems\n",
    "        ON ____.itemid = ____._____\n",
    "WHERE _____ = _____\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL, select the minimum, maximum, and average values of this test\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    _____,\n",
    "    _____,\n",
    "    _____\n",
    "FROM labevents\n",
    "    INNER JOIN d_labitems\n",
    "        ON labevents.itemid = d_labitems.itemid\n",
    "____ loinc_code = '2345-7';\"\"\"\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Python, select the first 10,000 rows. Call the resulting DataFrame glucose\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM labevents\n",
    "    _____\n",
    "        _____\n",
    "_____ _____\n",
    "LIMIT 10000;\n",
    "\"\"\"\n",
    "glucose = pd.read_sql(_____, conn)\n",
    "glucose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "glucose[\"valuenum\"].____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot\n",
    "sns.boxplot(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lab's value often doesn't mean much on its own. Sometimes we're mainly interested in whether or not a lab result is within the expected range. If it's outside of the range, then this might be an indicator that something is wrong. We can look at the **\"flag\"** attribute in `labevents` to see if it is abnormal or normal. \n",
    "\n",
    "Let's take a the values in the **\"flag\"** column of the DataFrame `glucose`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose.groupby(\"flag\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glucose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Note that the only value in this column is **\"abnormal\"**, and only 6,773 / 10,000 rows have this value. What about the other rows? How can we know which rows are normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing NULL values\n",
    "This column only contains a string value if the flag is **\"abnormal\"**. Otherwise, the column is left blank. We may want to fill these nulls  with the value **\"normal\"**. We can do this with either SQL or Python. Here we'll use SQL and will see an example later using Python.\n",
    "\n",
    "### Replacing NULL with SQL\n",
    "We can fill these null values in our SQL query by using the `coalesce` function. This will take the first non-null value in a list. So, for example,\n",
    "\n",
    "`coalesce(null, 'world!')` would return 'world!', while `coalesce('hello,', null)` would return 'hello'.\n",
    "\n",
    "### Discussion\n",
    "What would `coalesce('hello', 'world')` return?\n",
    "\n",
    "### TODO\n",
    "Change the query below so that SQL will return the value of the column `flag` if it is not null and will return `'normal'` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT labevents.subject_id,\n",
    "    hadm_id,\n",
    "   valuenum,\n",
    "    COALESCE(____, ____) AS 'flag',\n",
    "    labevents.valueuom AS 'units',\n",
    "    d_labitems.test_name,\n",
    "    d_labitems.loinc_code,\n",
    "    d_labitems.loinc_description\n",
    "FROM labevents\n",
    "    INNER JOIN d_labitems\n",
    "    ON labevents.itemid = d_labitems.itemid\n",
    "WHERE loinc_code = '2345-7'\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "glucose2 = pd.read_sql(query, conn)\n",
    "glucose2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glucose2.groupby(\"flag\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Create two plots:\n",
    "1. Generate a histogram of the `flag` column of df using either Pandas or Seaborn\n",
    "2. Generate a boxplot of the `valuenum` column stratified by flag (**hint:** remember when we stratified patient age of death by gender?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.____(x=____, ____=____, data=df, order=['abnormal', 'normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate functions\n",
    "Note that the tests above have multiple values for the same patient taken a few hours apart. It might be useful to group together all of the values for a single patient and perform operations on all of a patient's values. Let's use aggregate functions to determine the min, max, and average values for a patient during one hospital stay.\n",
    "\n",
    "### TODO\n",
    "Write a query which retrieves lab results for the LOINC code '2345-7' and groups the results together by **subject_id**. Calculate the minimum, maximum, and average values for each patient and name them 'min_value', 'max_value', and 'avg_value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    labevents.subject_id,\n",
    "    ____(valuenum) as 'min_value',\n",
    "    MAX(valuenum) as ____,\n",
    "    ____(____) as ____\n",
    "    INNER JOIN d_labitems\n",
    "    ON labevents.itemid = d_labitems.itemid\n",
    "WHERE loinc_code = '2345-7'\n",
    "GROUP BY subject_id\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "Plot the 'avg_value' column from the dataframe above. What kind of distribution does the lab test have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"avg_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vital Signs\n",
    "As we saw in Week 4, vital signs are taken frequently in medical visits. In a setting such as the ICU, vital signs will be monitored constantly in order to quickly detect and alert if anything is wrong.\n",
    "\n",
    "The `chartevents` table in MIMIC-II contains vitals measurements. Just like lab values, metadata about the measurements are stored separately. The table `d_chartitems` defines what these measurements. Let's look at what the first 25 alphabetical vital measurements are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    DISTINCT d_chartitems.label\n",
    "FROM d_chartitems\n",
    "LIMIT 25;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's query the first 1000 rows from `chartevents` to see what some actual measurements look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM mimic2.chartevents\n",
    "    INNER JOIN d_chartitems ON chartevents.itemid = d_chartitems.itemid\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood pressure\n",
    "Let's look at some measurements for blood pressure. I checked beforehand and found 4 tests which we could use. Their id's in `d_chartitems` are (6, 51, 455, 6701). Let's look at what these tests are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood pressure\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM d_chartitems\n",
    "WHERE itemid IN (6, 51, 455, 6701);\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's query `chartevents` to see what these measurements actually look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood pressure\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM mimic2.chartevents\n",
    "    INNER JOIN d_chartitems \n",
    "        ON chartevents.itemid = d_chartitems.itemid\n",
    "WHERE d_chartitems.itemid in (6, 51, 455, 6701)\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **semantics** of this table aren't always clear, so we can refer to the MIMIC documentation for some explanation.\n",
    "\n",
    "The values which we're interested in here are:\n",
    "- `\"value1num\"` - this represents the systolic blood pressure\n",
    "- `\"value2num\"` - this represents the diastolic blood pressure\n",
    "\n",
    "### TODO\n",
    "Write a query for these blood pressure measurements and assign aliases to these two values:\n",
    "- `\"value1num\"` should be called \"systolic_bp\"\n",
    "- `\"value2num\"` should be called \"diastolic_bp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood pressure\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    subject_id, \n",
    "    icustay_id, \n",
    "    charttime, \n",
    "    value1num as ____,\n",
    "    ____ as ____,\n",
    "    label\n",
    "FROM mimic2.chartevents\n",
    "    INNER join d_chartitems \n",
    "        ON chartevents.itemid = d_chartitems.itemid\n",
    "WHERE d_chartitems.itemid in (6, 51, 455, 6701)\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values\n",
    "### Discussion\n",
    "Some measurements are 0. Others are null. What do you think this means? What should we do with these rows?\n",
    "\n",
    "\n",
    "### Dealing with missing values in Python\n",
    "Earlier, we replaced `NULL` values using SQL. Let's look at some alternative ways to deal with this in Python.\n",
    "\n",
    "We can see which rows containing NULL values for a column by using **boolean indexing** with the `isna()` method of a Pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"systolic_bp\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Drop rows with missing values\n",
    "Use the `dropna()` method to drop rows with missing values. You can specify the columns in which to look for missing values by using the `subset` argument (the default is to drop any row with **any** missing value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop rows with NA or 0 value\n",
    "df2 = df.dropna(subset=[\"systolic_bp\", \"diastolic_bp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values\n",
    "The second option is to fill missing values with some calculated value from the column, such as the mean. This is called **data imputation** and is a common solution for when you don't want to throw out rows due to a missing value.\n",
    "\n",
    "- Calculate the mean value of **\"systolic_bp\"**. Save this as `systolic_mean`\n",
    "- Call `df[\"systolic_bp\"].fillna()`. This returns a new Series with the missing values replaced with `systolic_mean`. Save this as `systolic_no_na`\n",
    "- Assign this value to the **\"systolic_bp\"** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Fill with mean\n",
    "df[\"systolic_bp\"] = df[\"systolic_bp\"].fillna(df[\"systolic_bp\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systolic_mean = df[\"systolic_bp\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systolic_no_na = df[\"systolic_bp\"].fillna(systolic_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"systolic_bp\"] = systolic_no_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see which rows have missing values in **\"systolic_bp\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"systolic_bp\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Repeat this step with **\"diastolic_bp\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Vitals\n",
    "Now, let's plot these variables.\n",
    "\n",
    "### TODO\n",
    "Plot the distribution of systolic and diastolic blood pressures side-by-side. I've created two subplots next to each other. Call the `hist` method on the appropriate columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "df[\"systolic_bp\"].____(ax=ax1)\n",
    "df[____.____(ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Let's look at how these two readings are **correlated** with one another. The correlation of two variables measures how dependent the two variables are on one other - they tell us how related they are. \n",
    "\n",
    "We can do this in two ways. First, we'll plot a **scatterplot** which will allow us to visualize the relationship between one variable (systolic blood pressure) and another (diastolic). Next, we can calculate the correlation coefficient of the two variables by using the `corr` method of the columns in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Call the function `sns.scatterplot`. Plot 'diastolic_bp' on the x axis and 'systolic_bp' on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=____, __=____, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Call the `.corr()` method on `df['diastolic_bp']`. Pass in `df['systolic_bp']` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diastolic_bp'].____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Look at the scatterplot of the two blood pressure readings and the correlation coefficient returned by `.corr()`. What does this tell us about the relationship between these two variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "For homework, complete the following notebook. When you're done, save it as an HTML and submit it via Canvas:\n",
    "\n",
    "[./03-homework.ipynb](./03-homework.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
